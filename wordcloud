# coding: utf-8
from tkinter import *
import re
import requests
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from wordcloud import WordCloud, STOPWORDS
import urllib.request
import pandas as pd
import urllib.parse
from imageio import imread
import jieba, codecs
from lxml import html
from bs4 import BeautifulSoup
from bs4 import UnicodeDammit
import random
import time
import os


path = r'C:\Users\nepole\Desktop\新建文件夹 (2)'#图片地址,要自行更换
s =r'https://movie.douban.com/subject/***/'

def find_ID(name):   #name即剧名
    try:
        url1 = 'https://movie.douban.com/j/subject_suggest?q='
        url2 = urllib.parse.quote(name)  #URL只允许一部分ASCII字符，其他字符（如汉字）是不符合标准的，此时就要进行编码。
        url = url1 + url2  #生成针对该剧的链接，上面链接红字部分即为编码的name
        html = requests.get(url)  #访问链接，获取html页面的内容
        html = html.content.decode()  #对html的内容解码为utf-8格式
        html_list = html.replace('\/','/')  #将html中的\/全部转换成/，只是为了看着方便（不换也行）
        html_list = html_list.split('},{')  #将html页面中的每一个条目提取为列表的一个元素。
 
        #定义正则，目的是从html中提取想要的信息（根据title提取id）
        str_title = '"title":"' + name + '"'  ##匹配剧名name
        pattern_title = re.compile(str_title)
 
        str_id = '"id":"'+ '[0-9]*'   ##匹配该剧的id值
        pattern_id = re.compile(str_id)
 
        #从html_list中的每个item中提取对应的ID值
        id_list = []  #ID存放列表
        for l in html_list:  #遍历html_list
            find_results_title = re.findall(pattern_title,l,flags=0)  #找到匹配该剧name的条目item
            if find_results_title != []:  #如果有title=name的条目，即如果有匹配的结果
                find_results_id = re.findall(pattern_id,l,flags=0)  #从该匹配的item中的寻找对应的id之
                id_list.append(find_results_id)  #将寻找到的id值储存在id_list中
 
        #可能匹配到了多个ID（可能是同名不同剧），根据产生的id的数量，使剧名name匹配产生的id，使两个list相匹配
        name_list = [name] * len(id_list)  
 
        #对id_list的格式进行修整，使之成为标准列表格式
        id_list = str(id_list).replace('[','').replace(']','').replace("'",'').replace('"id":"','').replace(' ','')  
        id_list = id_list.split(',')
 
    except:  #如果不能正常运行上述代码（不能访问网页等），输出未成功的剧名name。
        print('ERROR:',name)
    return name_list,id_list

def generate_ID(nondup_name_list):  #给定剧单（剧名列表）
    name_list = []
    id_list = []
    error_list = []
    for name in nondup_name_list:  #遍历剧单中每个剧名
        try:
            item_name,item_id = find_ID(name)  #执行find_ID函数，返回该剧名的name-id对
            name_list.extend(item_name)  #储存name
            id_list.extend(item_id)  #储存id
        except:  #如果执行出现错误，则将失败的name储存在error_list中
            error_list.extend(name)
        time.sleep(1 + float(random.randint(1, 100)) / 20)  #防止账号被封，随机延迟
 
    if '' in id_list:  #除去异常的id
        id_list.remove('')
 
    if '' in error_list:  #除去异常的id
        error_list.remove('')    
 
    print(id_list)
    print(name_list)
 
    if error_list != []:
        print('未成功生成ID的剧名：',error_list)
    else:
        print('------------------------------全部成功生成豆瓣ID------------------------------------')
    return id_list,name_list




def spider_comment(movie_id, page):
    """
    爬取评论
    :param movie_id: 电影ID
    :param page: 爬取前N页
    :return: 评论内容
    """
    comment_list = []
    for i in range(page):
        url = 'https://movie.douban.com/subject/%s/comments?start=%s&limit=20&sort=new_score&status=P&percent_type=' \
              % (movie_id, (i - 1) * 20)

        req = requests.get(url).content

        soup = BeautifulSoup(req)
        comment_div_list = soup.select('#comments .comment-item')
        for comment_div in comment_div_list:
            comment_list.append(comment_div.select('.short')[0].text)
        print("当前页数:%s，总评论数:%s" % (i, len(comment_list)))

    return comment_list

def wordcloud(comment_list):

    #img = Image.open(r'C:\Users\nepole\Desktop\新建文件夹 (2)\alice_mask.png')#打开图片，填充非白字的部分
    img = Image.open('alice_mask.png')#同一目录下
    img_array = np.array(img) #将图片装换为数组
    wordlist = jieba.lcut(' '.join(comment_list))
    text = ' '.join(wordlist)
    print(text)
    wordcloud = WordCloud(
        font_path="./simkai.ttf",#防止乱码 ，出现框框
        background_color="white",
        max_font_size=80,
        stopwords=STOPWORDS,
        mask=img_array,          #图片背景数组为img_array
        width=1000,
        height=860,
        margin=2,                #余量
        ).generate(text)
    plt.imshow(wordcloud)
    plt.axis("on")
    plt.show()
    wordcloud.to_file(r'C:\Users\nepole\Desktop\新建文件夹 (2)\new.png')  #保存图片
# 主函数
if __name__ == '__main__':
	root = Tk()
	root.title('词云生成器')
	root.geometry('300x160')
	Label(root,text='电影名：').place(x=30,y=30)
	v1 = StringVar()
	e1 = Entry(root,textvariable=v1) #用*号代替用户输入的内容
	e1.place(x=80,y=30)
	def show():
		print('电影名字：%s' % v1.get())
		
		#url1=('https://movie.douban.com/subject_search?search_text=%s&cat=1002' % v1.get())为搜索地址
		nondup_name_list = ['%s'%v1.get()]
		id_list,name_list = generate_ID(nondup_name_list)
		if len(id_list)==0 : 
			print('无法查询到这部电影')
			e1.delete(0,END)    #获取完信息，清楚掉输入框的||0,END，表示从第0个到最后一个
		else:	
			print(id_list[0])
			movie_id = id_list[0]
			page = 8
			comment_list = spider_comment(movie_id, page)
			wordcloud(comment_list)
			e1.delete(0,END)    #获取完信息，清楚掉输入框的||0,END，表示从第0个到最后一个



	Button(root,text='获取信息',width=10,command=show).place(x=20,y=120)
	Button(root,text='退出',width=10,command=root.quit).place(x=180,y=120)

	mainloop()

	

